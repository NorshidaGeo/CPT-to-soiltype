{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb3a9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f92316a",
   "metadata": {},
   "source": [
    "# MLflow Experiment Tracking: Random Forest on Geotechnical Datasets\n",
    "\n",
    "This notebook demonstrates end-to-end experiment tracking with MLflow for geotechnical machine learning.\n",
    "\n",
    "What you'll learn:\n",
    "- How to set up a local MLflow tracking store (file-based) in this repository (`./experiments`).\n",
    "- How to create a small synthetic CPT-like dataset and train a Random Forest classifier.\n",
    "- How to track parameters, metrics, and artifacts (confusion matrix) with MLflow.\n",
    "- How to save trained models both as MLflow artifacts and to the local `models/` directory.\n",
    "- Optional: Repeat the workflow on a numeric-only slice of the provided earthquake dataset.\n",
    "\n",
    "Teaching flow:\n",
    "1. Briefly explain MLflow concepts (experiments, runs, params, metrics, artifacts).\n",
    "2. Run each cell live. Students run alongside and inspect outputs.\n",
    "\n",
    "Notes and constraints for this lesson:\n",
    "- CPU-only; no GPU dependencies.\n",
    "- Simple train/test split (no CV) to keep runtime fast and concepts clear.\n",
    "- Keep preprocessing minimal (Random Forest is robust to feature scaling).\n",
    "- No fixed global random seed (to illustrate natural variability across runs).\n",
    "- We'll only log a confusion matrix plot as an artifact (keeps focus)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832a35e7",
   "metadata": {},
   "source": [
    "## Setup: Imports and MLflow configuration\n",
    "We'll configure MLflow to use a local file-based tracking URI under the repository's `experiments/` directory. If it doesn't exist, we'll create it. We'll also pick a descriptive experiment name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2770ba54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow tracking URI set to: file:///C:/Users/TFH/git_projects/course-machine-learning-for-geotechnics/experiments/mlruns\n",
      "Experiment directory: C:\\Users\\TFH\\git_projects\\course-machine-learning-for-geotechnics\\experiments\\mlruns\n",
      "Models directory: C:\\Users\\TFH\\git_projects\\course-machine-learning-for-geotechnics\\models\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_theme()\n",
    "\n",
    "# Resolve project paths robustly whether the notebook is run from notebooks/ or repo root\n",
    "cwd = Path.cwd().resolve()\n",
    "repo_root_candidates = [cwd, cwd.parent]\n",
    "project_root: Path | None = None\n",
    "for base in repo_root_candidates:\n",
    "    if (base / \"experiments\").exists() and (base / \"models\").exists():\n",
    "        project_root = base\n",
    "        break\n",
    "if project_root is None:\n",
    "    # Fall back to parent of current working directory (common for notebooks/)\n",
    "    project_root = cwd.parent\n",
    "\n",
    "experiments_dir = project_root / \"experiments\" / \"mlruns\"\n",
    "experiments_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "models_dir = project_root / \"models\"\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Configure MLflow to use local file-based tracking store\n",
    "mlflow.set_tracking_uri(experiments_dir.as_uri())\n",
    "mlflow.set_experiment(\"rf_geotech_demo\")\n",
    "\n",
    "print(f\"MLflow tracking URI set to: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"Experiment directory: {experiments_dir}\")\n",
    "print(f\"Models directory: {models_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef4877b",
   "metadata": {},
   "source": [
    "## Create a small synthetic CPT-like dataset\n",
    "We'll synthesize a few common CPT features and assign simplified soil classes.\n",
    "- depth: m (0â€“30 m)\n",
    "- qc: cone resistance (MPa), higher in sands\n",
    "- fs: sleeve friction (MPa)\n",
    "- Rf: friction ratio (%) = 100 * fs / qc\n",
    "\n",
    "We'll generate three classes (1=gravel/sand-like, 2=silt-like, 3=clay-like) based on plausible value ranges with noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebda8c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "depth",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "qc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Rf",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "soil_class",
         "rawType": "int32",
         "type": "integer"
        }
       ],
       "ref": "3314ba81-cc56-419a-bdb2-c3479cdfbc11",
       "rows": [
        [
         "0",
         "25.88635044854661",
         "12.535763379985644",
         "0.14450847814481824",
         "1.152769669979075",
         "1"
        ],
        [
         "1",
         "10.831680623575163",
         "14.640120071154684",
         "0.1998885403075432",
         "1.3653476838716783",
         "1"
        ],
        [
         "2",
         "14.422509471159307",
         "14.899111252974585",
         "0.13752201481979234",
         "0.9230215983006119",
         "1"
        ],
        [
         "3",
         "10.093557412565865",
         "9.946199497962267",
         "0.3498566672827332",
         "3.5174909507335967",
         "1"
        ],
        [
         "4",
         "11.589926138321623",
         "8.406628686355473",
         "0.08216369061162636",
         "0.9773679042703954",
         "1"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>qc</th>\n",
       "      <th>fs</th>\n",
       "      <th>Rf</th>\n",
       "      <th>soil_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.886350</td>\n",
       "      <td>12.535763</td>\n",
       "      <td>0.144508</td>\n",
       "      <td>1.152770</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.831681</td>\n",
       "      <td>14.640120</td>\n",
       "      <td>0.199889</td>\n",
       "      <td>1.365348</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.422509</td>\n",
       "      <td>14.899111</td>\n",
       "      <td>0.137522</td>\n",
       "      <td>0.923022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.093557</td>\n",
       "      <td>9.946199</td>\n",
       "      <td>0.349857</td>\n",
       "      <td>3.517491</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.589926</td>\n",
       "      <td>8.406629</td>\n",
       "      <td>0.082164</td>\n",
       "      <td>0.977368</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       depth         qc        fs        Rf  soil_class\n",
       "0  25.886350  12.535763  0.144508  1.152770           1\n",
       "1  10.831681  14.640120  0.199889  1.365348           1\n",
       "2  14.422509  14.899111  0.137522  0.923022           1\n",
       "3  10.093557   9.946199  0.349857  3.517491           1\n",
       "4  11.589926   8.406629  0.082164  0.977368           1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Synthetic dataset size\n",
    "n = 900  # keep small for fast teaching runs\n",
    "\n",
    "# We'll allocate roughly equal class sizes\n",
    "n1 = n // 3\n",
    "n2 = n // 3\n",
    "n3 = n - n1 - n2\n",
    "\n",
    "# Class 1: sand/gravel-like (higher qc, lower Rf)\n",
    "depth1 = 30 * np.random.rand(n1)\n",
    "qc1 = np.random.normal(loc=12.0, scale=2.5, size=n1).clip(min=1e-3)\n",
    "fs1 = np.random.normal(loc=0.2, scale=0.08, size=n1).clip(min=1e-4)\n",
    "Rf1 = 100 * fs1 / qc1\n",
    "\n",
    "# Class 2: silt-like (moderate qc, moderate Rf)\n",
    "depth2 = 30 * np.random.rand(n2)\n",
    "qc2 = np.random.normal(loc=6.0, scale=1.5, size=n2).clip(min=1e-3)\n",
    "fs2 = np.random.normal(loc=0.25, scale=0.09, size=n2).clip(min=1e-4)\n",
    "Rf2 = 100 * fs2 / qc2\n",
    "\n",
    "# Class 3: clay-like (lower qc, higher Rf)\n",
    "depth3 = 30 * np.random.rand(n3)\n",
    "qc3 = np.random.normal(loc=2.5, scale=0.8, size=n3).clip(min=1e-3)\n",
    "fs3 = np.random.normal(loc=0.22, scale=0.07, size=n3).clip(min=1e-4)\n",
    "Rf3 = 100 * fs3 / qc3\n",
    "\n",
    "X = np.concatenate(\n",
    "    [\n",
    "        np.vstack([depth1, qc1, fs1, Rf1]).T,\n",
    "        np.vstack([depth2, qc2, fs2, Rf2]).T,\n",
    "        np.vstack([depth3, qc3, fs3, Rf3]).T,\n",
    "    ]\n",
    ")\n",
    "y = np.array([1] * n1 + [2] * n2 + [3] * n3)\n",
    "\n",
    "feature_names = [\"depth\", \"qc\", \"fs\", \"Rf\"]\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df[\"soil_class\"] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a6b09e",
   "metadata": {},
   "source": [
    "## Train/test split\n",
    "We'll use a simple train/test split to keep runtime and complexity low. No scaling or advanced preprocessing is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba80932f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((675, 4), (225, 4))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[feature_names].values\n",
    "y = df[\"soil_class\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f698f1",
   "metadata": {},
   "source": [
    "## Train Random Forest and track with MLflow\n",
    "We'll record: parameters, accuracy and F1 metrics, a confusion matrix figure artifact, the classification report text, and the trained model (both as an MLflow artifact and to `models/`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e651857f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/18 23:42:54 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/18 23:42:57 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/09/18 23:42:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.92, 0.9191444520391889)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helper to create and log a confusion matrix image as an MLflow artifact\n",
    "def log_confusion_matrix(\n",
    "    y_true, y_pred, labels, artifact_name=\"confusion_matrix_rf.png\"\n",
    "):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    fig, ax = plt.subplots(figsize=(4.5, 4.5), dpi=120)\n",
    "    disp.plot(ax=ax, cmap=\"Blues\", colorbar=False)\n",
    "    ax.set_title(\"Confusion Matrix\")\n",
    "    ax.grid(False)\n",
    "    fig.tight_layout()\n",
    "    out_path = Path.cwd() / artifact_name\n",
    "    fig.savefig(out_path)\n",
    "    plt.close(fig)\n",
    "    mlflow.log_artifact(str(out_path), artifact_path=\"plots\")\n",
    "    try:\n",
    "        out_path.unlink(missing_ok=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "# Random Forest hyperparameters (no fixed seed for illustration)\n",
    "params = {\n",
    "    \"n_estimators\": 200,\n",
    "    \"max_depth\": None,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"max_features\": \"sqrt\",\n",
    "}\n",
    "\n",
    "with mlflow.start_run(run_name=\"rf_cpt_synthetic\"):\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_text(\",\".join(feature_names), artifact_file=\"feature_columns.txt\")\n",
    "\n",
    "    clf = RandomForestClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1w = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"f1_weighted\", f1w)\n",
    "    mlflow.log_text(\n",
    "        classification_report(y_test, y_pred, digits=3),\n",
    "        artifact_file=\"classification_report.txt\",\n",
    "    )\n",
    "\n",
    "    # Confusion matrix artifact (only plot we log as per lesson scope)\n",
    "    unique_labels = np.unique(np.concatenate([y_train, y_test]))\n",
    "    log_confusion_matrix(y_test, y_pred, labels=unique_labels)\n",
    "\n",
    "    # Log model to MLflow (artifacts)\n",
    "    mlflow.sklearn.log_model(clf, artifact_path=\"model\")\n",
    "\n",
    "    # # Also save locally to models/ for easy reuse outside MLflow\n",
    "    # local_model_path = models_dir / \"rf_cpt_synthetic.pkl\"\n",
    "    # with open(local_model_path, \"wb\") as f:\n",
    "    #     pickle.dump(clf, f)\n",
    "\n",
    "    # print(f\"Logged metrics: accuracy={acc:.3f}, f1_weighted={f1w:.3f}\")\n",
    "    # print(f\"Local model saved to: {local_model_path}\")\n",
    "\n",
    "acc, f1w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3906a67d",
   "metadata": {},
   "source": [
    "## Explore MLflow UI (optional)\n",
    "Start the UI locally in a separate terminal to browse runs, parameters, metrics, and artifacts:\n",
    "\n",
    "1. Change directory to the experiments folder.\n",
    "2. Launch MLflow UI.\n",
    "\n",
    "Commands (PowerShell):\n",
    "\n",
    "```powershell\n",
    "cd \"$PSScriptRoot/..\"  # go to repo root if you're in notebooks/\n",
    "cd experiments\n",
    "uv run mlflow ui --port 5000\n",
    "```\n",
    "\n",
    "Then open http://127.0.0.1:5000 in your browser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9206197",
   "metadata": {},
   "source": [
    "## Optional: Earthquake dataset example (predicting tsunami flag)\n",
    "We'll reuse the same pattern on `data/raw/earthquake_data.csv` to predict whether an event has a tsunami flag (0/1).\n",
    "We only use numeric columns to keep preprocessing minimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bc1adce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((586, 10), (196, 10), array([478, 304], dtype=int64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and prepare earthquake data (numeric-only slice)\n",
    "data_raw_dir = project_root / \"data\" / \"raw\"\n",
    "eq_path = data_raw_dir / \"earthquake_data.csv\"\n",
    "eq_df = pd.read_csv(eq_path)\n",
    "\n",
    "# Select numeric features. We'll avoid heavy preprocessing or encoding.\n",
    "numeric_cols = [\n",
    "    \"magnitude\",\n",
    "    \"cdi\",\n",
    "    \"mmi\",\n",
    "    \"sig\",\n",
    "    \"nst\",\n",
    "    \"dmin\",\n",
    "    \"gap\",\n",
    "    \"depth\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "]\n",
    "target_col = \"tsunami\"  # 0/1\n",
    "eq_df = eq_df[numeric_cols + [target_col]].dropna()\n",
    "\n",
    "Xe = eq_df[numeric_cols].values\n",
    "ye = eq_df[target_col].values.astype(int)\n",
    "Xe_train, Xe_test, ye_train, ye_test = train_test_split(\n",
    "    Xe, ye, test_size=0.25, stratify=ye\n",
    ")\n",
    "Xe_train.shape, Xe_test.shape, np.bincount(ye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b43e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/18 23:41:52 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/18 23:41:54 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/09/18 23:41:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged EQ metrics: accuracy=0.898, f1_weighted=0.899\n",
      "Local EQ model saved to: C:\\Users\\TFH\\git_projects\\course-machine-learning-for-geotechnics\\models\\rf_earthquake_tsunami.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8979591836734694, 0.8988903129689879)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_eq = {\n",
    "    \"n_estimators\": 300,\n",
    "    \"max_depth\": None,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"max_features\": \"sqrt\",\n",
    "}\n",
    "\n",
    "with mlflow.start_run(run_name=\"rf_earthquake_tsunami\"):\n",
    "    mlflow.set_experiment(\"rf_geotech_demo\")  # ensure same experiment\n",
    "    mlflow.log_params(params_eq)\n",
    "    mlflow.log_text(\",\".join(numeric_cols), artifact_file=\"feature_columns.txt\")\n",
    "\n",
    "    clf_eq = RandomForestClassifier(**params_eq)\n",
    "    clf_eq.fit(Xe_train, ye_train)\n",
    "\n",
    "    ye_pred = clf_eq.predict(Xe_test)\n",
    "    acc_eq = accuracy_score(ye_test, ye_pred)\n",
    "    f1w_eq = f1_score(ye_test, ye_pred, average=\"weighted\")\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", acc_eq)\n",
    "    mlflow.log_metric(\"f1_weighted\", f1w_eq)\n",
    "    mlflow.log_text(\n",
    "        classification_report(ye_test, ye_pred, digits=3),\n",
    "        artifact_file=\"classification_report.txt\",\n",
    "    )\n",
    "\n",
    "    log_confusion_matrix(ye_test, ye_pred, labels=np.unique(ye))\n",
    "    mlflow.sklearn.log_model(clf_eq, artifact_path=\"model\")\n",
    "\n",
    "    # local_eq_model_path = models_dir / \"rf_earthquake_tsunami.pkl\"\n",
    "    # with open(local_eq_model_path, \"wb\") as f:\n",
    "    #     pickle.dump(clf_eq, f)\n",
    "\n",
    "    # print(f\"Logged EQ metrics: accuracy={acc_eq:.3f}, f1_weighted={f1w_eq:.3f}\")\n",
    "    # print(f\"Local EQ model saved to: {local_eq_model_path}\")\n",
    "\n",
    "acc_eq, f1w_eq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9bdfea",
   "metadata": {},
   "source": [
    "## Student task\n",
    "- Modify Random Forest hyperparameters (e.g., `n_estimators`, `max_depth`).\n",
    "- Re-run the training cells to generate new MLflow runs.\n",
    "- Open the MLflow UI and compare metrics across runs.\n",
    "- Optional: Add one more numeric feature to the earthquake example (e.g., compute `magnitude^2`) and see if it impacts performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpt-to-soiltype",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
